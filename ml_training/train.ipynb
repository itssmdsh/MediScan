{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c423858",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666278e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# ----------------------------\n",
    "DATA_ROOT = \"/kaggle/input/skindiseasedataset/SkinDisease/SkinDisease\"\n",
    "SELECTED_CLASSES = ['Acne', 'Eczema', 'Psoriasis', 'Warts', 'SkinCancer', 'Unknown_Normal']\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_DIR = \"./outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, \"skin_disease_resnet18.pth\")\n",
    "LABELS_SAVE_PATH = os.path.join(OUTPUT_DIR, \"labels.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a373e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Reproducibility (optional)\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721acfa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Data transforms\n",
    "# ============================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6298aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset + filter selected classes\n",
    "# ============================================================\n",
    "train_dir = os.path.join(DATA_ROOT, \"train\")\n",
    "test_dir = os.path.join(DATA_ROOT, \"test\")\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "original_class_to_idx = train_data.class_to_idx\n",
    "\n",
    "# Keep only selected classes that exist in dataset mapping\n",
    "selected_idx = {\n",
    "    original_class_to_idx[cls]: cls\n",
    "    for cls in SELECTED_CLASSES\n",
    "    if cls in original_class_to_idx\n",
    "}\n",
    "\n",
    "assert len(selected_idx) > 0, \"No selected classes found in dataset!\"\n",
    "\n",
    "def remap_samples(samples):\n",
    "    \"\"\"\n",
    "    Converts original ImageFolder labels to new labels based on SELECTED_CLASSES order.\n",
    "    Filters out samples not in selected classes.\n",
    "    \"\"\"\n",
    "    remapped = []\n",
    "    for path, label in samples:\n",
    "        if label in selected_idx:\n",
    "            cls_name = selected_idx[label]\n",
    "            new_label = SELECTED_CLASSES.index(cls_name)\n",
    "            remapped.append((path, new_label))\n",
    "    return remapped\n",
    "\n",
    "# Remap\n",
    "train_data.samples = remap_samples(train_data.samples)\n",
    "test_data.samples = remap_samples(test_data.samples)\n",
    "\n",
    "train_data.targets = [label for _, label in train_data.samples]\n",
    "test_data.targets = [label for _, label in test_data.samples]\n",
    "\n",
    "train_data.classes = SELECTED_CLASSES\n",
    "test_data.classes = SELECTED_CLASSES\n",
    "\n",
    "train_data.class_to_idx = {cls: i for i, cls in enumerate(SELECTED_CLASSES)}\n",
    "test_data.class_to_idx = {cls: i for i, cls in enumerate(SELECTED_CLASSES)}\n",
    "\n",
    "print(\"Selected classes:\", SELECTED_CLASSES)\n",
    "print(\"Train samples:\", len(train_data))\n",
    "print(\"Test samples:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af296472",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "# ============================================================\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978de902",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model: ResNet18 (ImageNet pretrained)\n",
    "# ============================================================\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(SELECTED_CLASSES))\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb7bf1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "# ============================================================\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch + 1}/{NUM_EPOCHS}]\")\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Training {epoch + 1}/{NUM_EPOCHS}\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / max(1, len(train_loader))\n",
    "    acc = 100.0 * correct / max(1, total)\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "    print(f\"Train Loss: {avg_loss:.4f} | Train Accuracy: {acc:.2f}%\")\n",
    "    print(f\"Epoch time: {time.time() - epoch_start:.2f} sec\")\n",
    "\n",
    "print(f\"\\nTotal Training Time: {time.time() - start_time:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8e050",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save model + labels (GitHub ready)\n",
    "# ============================================================\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"\\n✅ Model weights saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "with open(LABELS_SAVE_PATH, \"w\") as f:\n",
    "    json.dump(SELECTED_CLASSES, f, indent=2)\n",
    "\n",
    "print(f\"✅ Labels saved to: {LABELS_SAVE_PATH}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Evaluation\n",
    "# ============================================================\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=SELECTED_CLASSES))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Confusion Matrix (Matplotlib only - no seaborn needed)\n",
    "# ============================================================\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(SELECTED_CLASSES))\n",
    "plt.xticks(tick_marks, SELECTED_CLASSES, rotation=45, ha=\"right\")\n",
    "plt.yticks(tick_marks, SELECTED_CLASSES)\n",
    "\n",
    "# Write numbers inside cells\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b6be3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Utility: Predict from Image URL\n",
    "# ============================================================\n",
    "def predict_from_url(image_url, model, transform, class_names):\n",
    "    model.eval()\n",
    "\n",
    "    response = requests.get(image_url, timeout=20)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        conf, predicted = torch.max(probs, 1)\n",
    "\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    confidence = conf.item()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class} ({confidence*100:.2f}%)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "\n",
    "# Example URL prediction\n",
    "image_url = \"https://images.ctfassets.net/4f3rgqwzdznj/6V6F0gVHYPSTmNARliytAY/4fee36cfb2f433f8b43d85ecef211345/eczema-severe-eczema-mistakes.png\"\n",
    "predicted, conf = predict_from_url(image_url, model, test_transform, SELECTED_CLASSES)\n",
    "print(\"Predicted Disease:\", predicted, \"| Confidence:\", conf)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Utility: Predict from local image path\n",
    "# ============================================================\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        conf, predicted = torch.max(probs, 1)\n",
    "\n",
    "    predicted_class = class_names[predicted.item()]\n",
    "    confidence = conf.item()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class} ({confidence*100:.2f}%)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Example:\n",
    "# predicted, conf = predict_image(\"/kaggle/input/....jpg\", model, test_transform, SELECTED_CLASSES)\n",
    "# print(predicted, conf)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
